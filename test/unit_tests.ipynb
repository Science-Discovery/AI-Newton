{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "work_dir = os.path.abspath('..')\n",
    "print(work_dir)\n",
    "os.chdir(work_dir)\n",
    "from aiphy import Theorist\n",
    "from aiphy.experiment.basic import motion0_3d_config, motion_3d_config, collision_y_config, collision_nh_config\n",
    "from aiphy.experiment.ground_laboratory import gravity_config\n",
    "from aiphy.experiment.cosmos import celestial_2_xy_config, celestial_3_config\n",
    "from aiphy.core import Exp\n",
    "import aiphy.core as core\n",
    "from aiphy.parsing import *\n",
    "from aiphy.dataplot import plot_data, plot_normaldata\n",
    "import sympy as sp\n",
    "# from aiphy.experiment.oscillation_2spring import oscillation_2spring_config\n",
    "import random\n",
    "\n",
    "EXAMPLE_PATH = \"data/test_cases/example_1\"\n",
    "\n",
    "INIT_TIME_LIMIT = 5\n",
    "MUL = 3\n",
    "MAX_ACTIONS = 7\n",
    "BIAS = 5\n",
    "ID = 5\n",
    "\n",
    "FILE_NAME = f\"example_1-{INIT_TIME_LIMIT}m{MUL}a{MAX_ACTIONS}p{BIAS}\".replace(\".\", \"-\")\n",
    "\n",
    "# Iterately create the path\n",
    "FILE_PATH_PARENT = EXAMPLE_PATH + \"/\" + FILE_NAME\n",
    "if ID is None:\n",
    "    FILE_PATH = FILE_PATH_PARENT + '/' + FILE_NAME\n",
    "else:\n",
    "    FILE_PATH = FILE_PATH_PARENT + '/' + FILE_NAME + f\"-{ID}\"\n",
    "\n",
    "theorist = Theorist.read_from_file(FILE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sympy as sp\n",
    "import numpy as np\n",
    "import re\n",
    "from aiphy.core import sentence, Concept\n",
    "exp_name = \"motion_3d\"\n",
    "spm = theorist.specific[exp_name]\n",
    "knowledge = theorist.knowledge\n",
    "general = theorist.general\n",
    "invalid_exps = lambda x: set(knowledge.fetch_exps) - set(general.general_laws[x].valid_experiments)\n",
    "calc = lambda x: theorist.calc_expr(Exp(x), exp_name)\n",
    "spexp = lambda x: spm._sympy_of_raw_defi(spm.expand_exp(Exp(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compensate concepts and gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exprs = ['D[A[1]]/D[t[0]] * E[2]', 'D[B[1]]/D[t[0]] * F[2]']\n",
    "pats = {\"$1$\": {'A', 'B', 'C'}, \"$2$\": {'E', 'F', 'G'}}\n",
    "extract_expression_pattern(exprs, pats, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetry_collections = {\"$1$\": {\"posx\": \"posx\", \"posy\": \"posy\", \"posz\": \"posz\"},\n",
    "                        \"$2$\": {\"C_01\": \"posx\", \"C_04\": \"posy\", \"C_27\": \"posz\"},\n",
    "                        \"$3$\": {\"C_136\": \"posx\", \"C_99\": \"posy\", \"C_28\": \"posz\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_single_relevant_direction(expr: Exp, symmetry_collections: dict[str, dict[str, str]]) -> dict[str: set[str]]:\n",
    "    # symmetry_collections: {pattern: {atom: direction}}\n",
    "    all_atom_names: set[str] = {atm.name for atm in expr.all_atoms}\n",
    "    relevant_directions = {}  # {direction: set[pattern]}\n",
    "    for atom in all_atom_names - {\"t\"} - {intr for intr in knowledge.fetch_intrinsic_concepts.keys()\n",
    "        if \"pos\" not in str(spm._sympy_of_raw_defi(spm.expand_exp(Exp(str(knowledge.fetch_intrinsic_by_name(intr)).split(\"|- \")[1][:-1]))))}:\n",
    "        flag = False\n",
    "        for patt, equivs in symmetry_collections.items():\n",
    "            if atom in equivs:\n",
    "                if equivs[atom] not in relevant_directions:\n",
    "                    relevant_directions[equivs[atom]] = set()\n",
    "                relevant_directions[equivs[atom]].add(patt)\n",
    "                flag = True\n",
    "                break\n",
    "        if not flag:\n",
    "            relevant_directions = {}\n",
    "            break\n",
    "        if len(relevant_directions) > 1:\n",
    "            break\n",
    "    return relevant_directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{intr for intr in knowledge.fetch_intrinsic_concepts.keys()\n",
    " if \"pos\" not in str(spm._sympy_of_raw_defi(spm.expand_exp(Exp(str(knowledge.fetch_intrinsic_by_name(intr)).split(\"|- \")[1][:-1]))))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_to_gen = {}\n",
    "for name in knowledge.fetch_concepts.keys():\n",
    "    concept = knowledge.fetch_concept_by_name(name)\n",
    "    if concept is None:\n",
    "        continue\n",
    "    res = check_single_relevant_direction(concept.exp, symmetry_collections)\n",
    "    if len(res) == 1:\n",
    "        concept_to_gen[name] = res\n",
    "concept_to_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetry_collections_inversed = {patt: {direction: atom for atom, direction in equivs.items()} for patt, equivs in symmetry_collections.items()}\n",
    "print(symmetry_collections_inversed)\n",
    "for name, patt_dict in concept_to_gen.items():\n",
    "    exist_concept = knowledge.fetch_concept_by_name(name)\n",
    "    patts: set[str] = list(patt_dict.values())[0]\n",
    "    dir2patt: dict[str, set[str]] = {direction: patts for direction in {\"posx\", \"posy\", \"posz\"} - set(patt_dict.keys())}\n",
    "    template = extract_expression_pattern([str(exist_concept.exp)],\n",
    "                                        {patt: set(direc.keys()) for patt, direc in symmetry_collections.items()})[0]\n",
    "    if template is None:\n",
    "        continue\n",
    "    print('-'*10)\n",
    "    print(name, \":\")\n",
    "    print(template)\n",
    "    print(exist_concept.exp)\n",
    "    for direction, set_patts in dir2patt.items():\n",
    "        concept_exp_str: str = template\n",
    "        for patt in set_patts:\n",
    "            concept_exp_str = concept_exp_str.replace(patt, symmetry_collections_inversed[patt][direction])\n",
    "        concept_exp: Exp = Exp(concept_exp_str)\n",
    "        concept = knowledge.generalize_to_normal_concept(exp_name, concept_exp)\n",
    "        if exist_concept.is_sum:\n",
    "            concept = Concept.Mksum(list(exist_concept.objtype_id_map.keys())[0], concept)\n",
    "        concept_name = theorist.register_concept(concept, spm)\n",
    "        if concept_name is not None:\n",
    "            print(concept_name)\n",
    "            print(knowledge.fetch_concept_by_name(concept_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symmetry_collections = {\"$1$\": {\"posx\": \"posx\", \"posy\": \"posy\", \"posz\": \"posz\"},\n",
    "                        \"$2$\": {\"C_01\": \"posx\", \"C_04\": \"posy\", \"C_27\": \"posz\"},\n",
    "                        \"$3$\": {\"C_136\": \"posx\", \"C_99\": \"posy\", \"C_28\": \"posz\"},\n",
    "                        \"$4$\": {\"C_142\": \"posx\", \"C_100\": \"posy\", \"C_1814\": \"posz\"}}\n",
    "symmetry_collections_inversed = {patt: {direction: atom for atom, direction in equivs.items()} for patt, equivs in symmetry_collections.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc_list = list(general.general_conclusions.values())\n",
    "for gc in gc_list:\n",
    "    gc_exp_str = str(gc.relevant_concept.exp) if gc.indication == \"ForAll\" else str(gc.relevant_concept).split(\"|- \")[1]\n",
    "    patt_matched = extract_expression_pattern(expand_expression(gc_exp_str),\n",
    "                                              {patt: set(direc.keys()) for patt, direc in symmetry_collections.items()},\n",
    "                                              minimal_terms=2)\n",
    "    if patt_matched[0] is not None:\n",
    "        print(gc)\n",
    "        print(patt_matched)\n",
    "        if len(patt_matched[1]) > 1:\n",
    "            raise ValueError(\"More than one pattern matched\")\n",
    "        if gc.indication == \"Sum\":\n",
    "            pattern = patt_matched[0]\n",
    "            exist_set = list(patt_matched[1].values())[0]\n",
    "            if len(exist_set) != 2:\n",
    "                continue\n",
    "            concept_name_to_append = list(set(symmetry_collections[pattern].keys()) - exist_set)[0]\n",
    "            print(\"concept_name_to_append:\", concept_name_to_append)\n",
    "            concept_to_append = knowledge.gen_atom_concept(concept_name_to_append)\n",
    "            if concept_to_append is None:\n",
    "                continue\n",
    "            new_concept = concept_to_append + gc.relevant_concept\n",
    "            print(new_concept)\n",
    "            general.create_general_law_from_old(exp_name, gc,\n",
    "                                                       new_concept,\n",
    "                                                       reset_father=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general.general_conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theorist.theoretical_analysis(exp_name, ver='ver3',\n",
    "                              name_list=['C_61', 'cx'],\n",
    "                              max_actions=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet\n",
    "\n",
    "# 检测文件编码\n",
    "def detect_encoding(file_path: str) -> str:\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "    result = chardet.detect(raw_data)\n",
    "    return result['encoding']\n",
    "\n",
    "# 读取文件并解析数据\n",
    "def parse_log_file(file_path: str):\n",
    "    epochs = []\n",
    "    losses = []\n",
    "\n",
    "    # 检测文件编码\n",
    "    encoding = detect_encoding(file_path)\n",
    "    print(f\"检测到的文件编码: {encoding}\")\n",
    "\n",
    "    # 使用检测到的编码打开文件\n",
    "    with open(file_path, 'r', encoding=encoding) as file:\n",
    "        for line in file:\n",
    "            # 使用正则表达式提取 epoch 和 loss\n",
    "            match = re.match(r\"epoch\\s*=\\s*(\\d+),\\s*loss\\s*=\\s*([\\d.e+-]+)\", line)\n",
    "            if match:\n",
    "                epoch = int(match.group(1))\n",
    "                loss = float(match.group(2))\n",
    "                epochs.append(epoch)\n",
    "                losses.append(loss)\n",
    "\n",
    "    return epochs, losses\n",
    "\n",
    "# 绘制 loss 关于 epoch 的变化图（对数坐标）\n",
    "def plot_loss_vs_epoch(epochs, losses, log_scale: bool = True):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, losses, marker='o', linestyle='-', color='b', label='Loss')\n",
    "\n",
    "    # 设置对数坐标\n",
    "    if log_scale:\n",
    "        plt.yscale('log')  # Y 轴使用对数坐标\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss (log scale)' if log_scale else 'Loss')\n",
    "    plt.title('Loss vs Epoch (Log Scale)' if log_scale else 'Loss vs Epoch')\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")  # 添加网格线\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# 主程序\n",
    "file_path = \"temp/nn_test_concept_grp_epoch_loss.txt\"  # 替换为你的文件路径\n",
    "epochs, losses = parse_log_file(file_path)\n",
    "plot_loss_vs_epoch(epochs, losses, log_scale=True)  # 设置为 True 使用对数坐标"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot concepts-epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "work_dir = os.path.abspath('..')\n",
    "os.chdir(work_dir)\n",
    "\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv('data/concepts-epoch.csv', header=None)\n",
    "\n",
    "# 初始化存储结果的列表\n",
    "concepts = []\n",
    "means = []\n",
    "mins = []\n",
    "maxs = []\n",
    "\n",
    "# 逐行处理数据\n",
    "for index, row in df.iterrows():\n",
    "    # 第一列是概念名（带双引号），需要去掉双引号\n",
    "    concept = row[0].strip('\"')\n",
    "    \n",
    "    # 后面的列是epoch数据，忽略最后一个空值（因为每行末尾有逗号）\n",
    "    epochs = row[1:-1].astype(int)\n",
    "    \n",
    "    # 计算平均值、标准差、最小值和最大值\n",
    "    mean = np.mean(epochs)\n",
    "    std = np.std(epochs)\n",
    "    min_epoch = mean - std\n",
    "    max_epoch = mean + std\n",
    "    \n",
    "    # 存储结果\n",
    "    concepts.append(concept)\n",
    "    means.append(mean)\n",
    "    mins.append(min_epoch)\n",
    "    maxs.append(max_epoch)\n",
    "\n",
    "# 将结果存储在DataFrame中\n",
    "results = pd.DataFrame({\n",
    "    'Concept': concepts,\n",
    "    'Mean': means,\n",
    "    'Min': mins,\n",
    "    'Max': maxs\n",
    "})\n",
    "\n",
    "# 按照平均值排序\n",
    "results = results.sort_values(by='Mean')\n",
    "\n",
    "# 绘制统计图\n",
    "plt.figure(figsize=(10, len(results) * 0.5))\n",
    "\n",
    "# 绘制每个概念的横线和error bar\n",
    "for i, (concept, mean, min_epoch, max_epoch) in enumerate(zip(results['Concept'], results['Mean'], results['Min'], results['Max'])):\n",
    "    # 绘制横线\n",
    "    plt.hlines(y=i, xmin=min_epoch, xmax=max_epoch, colors='blue', lw=2)\n",
    "    \n",
    "    # 绘制error bar的短竖线\n",
    "    plt.vlines(x=min_epoch, ymin=i-0.1, ymax=i+0.1, colors='black', lw=2)  # 最小值竖线\n",
    "    plt.vlines(x=max_epoch, ymin=i-0.1, ymax=i+0.1, colors='black', lw=2)  # 最大值竖线\n",
    "    \n",
    "    # 标注平均值\n",
    "    plt.plot(mean, i, 'ro', markersize=8)\n",
    "\n",
    "# 设置纵轴标签为数学符号形式\n",
    "plt.yticks(range(len(results)), [f'${concept}$' for concept in results['Concept']])\n",
    "\n",
    "# 设置横轴标签\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Concepts')\n",
    "\n",
    "# 设置标题\n",
    "plt.title('Epoch Statistics for Important Concepts')\n",
    "\n",
    "# 显示图形\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
